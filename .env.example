# ============================================================================
# Werewolf AI Game - 环境配置模板
# ============================================================================
#
# 快速开始（3步）：
# 1. 复制此文件：cp .env.example .env
# 2. 填写必需配置：JWT_SECRET_KEY（OPENAI_API_KEY 可选，不配则建议设置 LLM_USE_MOCK=true）
# 3. 启动服务：docker compose up
#
# ============================================================================

# ----------------------------------------------------------------------------
# 核心配置（必需 ⚠️）
# ----------------------------------------------------------------------------

# OpenAI API 配置（可选 - 不配置时建议设置 LLM_USE_MOCK=true）
# 获取地址：https://platform.openai.com/api-keys
OPENAI_API_KEY=

# JWT 认证密钥（必需 - 用于玩家身份验证）
# 生成建议：openssl rand -hex 32
# 或随机生成一个足够长的字符串（至少32个字符）
JWT_SECRET_KEY=

# Admin Key（管理接口认证，未设置会告警）
# 生成建议：openssl rand -hex 16
ADMIN_KEY=

# Admin Key 开关（生产环境建议关闭）
ADMIN_KEY_ENABLED=false

# ----------------------------------------------------------------------------
# 基础配置（推荐）
# ----------------------------------------------------------------------------

# AI 模型设置
LLM_MODEL=gpt-4o-mini
LLM_MAX_RETRIES=2
LLM_USE_MOCK=false

# OpenAI 自定义配置（可选）
# OPENAI_BASE_URL=https://api.openai.com/v1

# 应用设置
DEBUG=false
LOG_LEVEL=INFO

# CORS 跨域配置（compose 下前端经 nginx 反代走同源通常不需要，直连后端端口调试时需要）
# CORS_ORIGINS=http://localhost:8081,http://127.0.0.1:8081

# 控制 debug-messages API 端点的访问权限
DEBUG_MODE=false

# 数据存储目录
DATA_DIR=data

# JWT 高级配置（可选）
JWT_ALGORITHM=HS256
JWT_EXPIRE_MINUTES=10080

# ----------------------------------------------------------------------------
# OAuth 单点登录配置（可选）
# ----------------------------------------------------------------------------
# 支持 linux.do OAuth2 登录，需在 linux.do 开发者后台创建应用

# OAuth 应用凭证（从 linux.do 开发者后台获取）
# LINUXDO_CLIENT_ID=your_client_id
# LINUXDO_CLIENT_SECRET=your_client_secret

# OAuth 回调地址（需与 linux.do 后台配置一致）
# LINUXDO_REDIRECT_URI=https://your-domain.com/api/auth/callback/linuxdo

# OAuth 高级配置（通常无需修改）
# LINUXDO_AUTHORIZE_URL=https://linux.do/oauth2/authorize
# LINUXDO_TOKEN_URL=https://linux.do/oauth2/token
# LINUXDO_USERINFO_URL=https://linux.do/oauth2/userinfo
# LINUXDO_SCOPES=openid email profile

# ----------------------------------------------------------------------------
# AI 对局分析配置（可选）
# ----------------------------------------------------------------------------

# 分析专用模型（推荐使用高级模型以获得更好的分析质量）
ANALYSIS_MODEL=gpt-4o

# 分析模式：comprehensive（详细，3-5分钟）| quick（快速，1-2分钟）
ANALYSIS_MODE=comprehensive

# 分析语言：auto（自动检测）| zh（中文）| en（英文）
ANALYSIS_LANGUAGE=auto

# 分析结果缓存（避免重复计算）
ANALYSIS_CACHE_ENABLED=true

# 分析生成参数
ANALYSIS_MAX_TOKENS=4000
ANALYSIS_TEMPERATURE=0.7

# 分析专用 Provider（可选，不设置则使用默认 OpenAI 配置）
# 可选值：openai, deepseek, anthropic, moonshot, qwen, glm, doubao, minimax
# ANALYSIS_PROVIDER=

# ----------------------------------------------------------------------------
# 多 AI Provider 配置（高级 - 可选）
# ----------------------------------------------------------------------------
# 支持的 Provider：OPENAI, ANTHROPIC, DEEPSEEK, MOONSHOT, QWEN, GLM, DOUBAO, MINIMAX
# 每个 Provider 支持以下配置项：{PREFIX}_API_KEY, {PREFIX}_BASE_URL, {PREFIX}_MODEL,
# {PREFIX}_MAX_RETRIES, {PREFIX}_TEMPERATURE, {PREFIX}_MAX_TOKENS

# Deepseek 配置
# DEEPSEEK_API_KEY=
# DEEPSEEK_BASE_URL=https://api.deepseek.com/v1
# DEEPSEEK_MODEL=deepseek-chat

# Anthropic Claude 配置
# ANTHROPIC_API_KEY=
# ANTHROPIC_BASE_URL=https://api.anthropic.com/v1
# ANTHROPIC_MODEL=claude-3-haiku-20240307

# Moonshot (月之暗面) 配置
# MOONSHOT_API_KEY=
# MOONSHOT_BASE_URL=https://api.moonshot.cn/v1
# MOONSHOT_MODEL=moonshot-v1-8k

# Qwen (通义千问) 配置
# QWEN_API_KEY=
# QWEN_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
# QWEN_MODEL=qwen-turbo

# GLM (智谱清言) 配置
# GLM_API_KEY=
# GLM_BASE_URL=https://open.bigmodel.cn/api/paas/v4
# GLM_MODEL=glm-4-flash

# Doubao (豆包) 配置
# DOUBAO_API_KEY=
# DOUBAO_BASE_URL=https://ark.cn-beijing.volces.com/api/v3
# DOUBAO_MODEL=doubao-pro-4k

# MiniMax 配置
# MINIMAX_API_KEY=
# MINIMAX_BASE_URL=https://api.minimax.chat/v1
# MINIMAX_MODEL=abab6.5s-chat

# 自定义 Provider（使用 AI_PROVIDER_{1..9}_* 格式）
# AI_PROVIDER_1_NAME=custom
# AI_PROVIDER_1_API_KEY=your_api_key
# AI_PROVIDER_1_BASE_URL=https://your-api.com/v1
# AI_PROVIDER_1_MODEL=your-model

# ----------------------------------------------------------------------------
# 玩家级别 AI 配置（高级 - 可选）
# ----------------------------------------------------------------------------
# 为不同座位号（2-9）配置不同的 AI provider 和参数
# 用于实现多样化 AI 对战

# 示例：为玩家 2 配置专属 LLM
# AI_PLAYER_2_API_KEY=your_api_key
# AI_PLAYER_2_BASE_URL=https://api.openai.com/v1
# AI_PLAYER_2_MODEL=gpt-4o-mini
# AI_PLAYER_2_TEMPERATURE=0.7
# AI_PLAYER_2_MAX_TOKENS=500

# 批量映射玩家到 provider（JSON 格式）
# AI_PLAYER_MAPPING={"2":"openai","3":"deepseek","4":"anthropic"}

# 单独映射特定玩家到 provider
# AI_PLAYER_2_PROVIDER=deepseek
# AI_PLAYER_3_PROVIDER=openai

# ----------------------------------------------------------------------------
# 前端配置（可选 - 仅本地开发需要）
# ----------------------------------------------------------------------------
# Docker Compose 部署时前端通过 nginx 反代访问后端，无需配置
# 本地开发时如需直连后端，可配置以下变量

# 后端 API 地址（本地开发用）
# VITE_API_URL=http://localhost:8082
# VITE_API_BASE_URL=http://localhost:8082

# Sentry 错误监控（可选）
# VITE_SENTRY_DSN=https://xxx@sentry.io/xxx
# VITE_SENTRY_ENV=production
# VITE_SENTRY_TRACES_SAMPLE_RATE=0.1
# VITE_SENTRY_ENABLE_REPLAY=false
# VITE_SENTRY_REPLAYS_SESSION_SAMPLE_RATE=0.1
# VITE_SENTRY_REPLAYS_ON_ERROR_SAMPLE_RATE=1.0

# ----------------------------------------------------------------------------
# 配置验证
# ----------------------------------------------------------------------------
# 配置完成后，运行以下命令验证配置是否正确：
#   cd backend && python verify_config.py
#
# 验证工具会检查：
# ✓ 必需的环境变量是否设置
# ✓ Provider 配置是否有效
# ✓ API 密钥格式是否正确
# ✓ 分析配置是否完整
#
# 💡 提示：如果你刻意使用纯 mock 模式（不配任何 API_KEY），
#    verify_config.py 的报错可忽略，或设置 LLM_USE_MOCK=true 后直接启动
#
# ============================================================================
# 最小配置示例（仅 OpenAI）
# ============================================================================
# OPENAI_API_KEY=sk-your-key-here
# JWT_SECRET_KEY=your-random-secret-key-at-least-32-characters-long
#
# 这是最简配置，足以启动游戏和分析功能
# ============================================================================
